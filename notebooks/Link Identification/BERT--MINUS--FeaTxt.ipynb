{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d0c84a",
   "metadata": {},
   "source": [
    "# Implementation of the Kuribayashi BERT minus model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2546f",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe395cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers --upgrade\n",
    "!pip install ipywidgets\n",
    "!pip install IProgress\n",
    "!pip install datasets\n",
    "!pip install torch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35962f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertModel, BertForSequenceClassification\n",
    "from transformers import BatchEncoding, default_data_collator, DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import datasets\n",
    "from datasets import load_metric\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05e9900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.25.1\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34304b1b",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2338037a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c58960",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14212fb9",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "0c699094-439f-4dda-85a9-815e7948540c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FILE = '/notebooks/KURI-BERT/notebooks/full_formula_w_fts/Link_Identification_Task/pe_dataset_for_bert_minus_w_fts_combined_link_task.pt'\n",
    "RESULTS_FOLDER = '/notebooks/KURI-BERT/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "698de207",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "35aada91-232a-421e-a28f-94b359c6d65d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6803bf",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "dc52e71e-65fa-4946-acdf-e4fffe9d0f79",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e3071",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "013a6d64-65e7-4189-a468-40ecfd8a6736",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09989f64",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "626737f9-ff56-4992-b72b-60750375e455",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset = torch.load(DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9684d15",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f61f5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 0\n",
    "MAX_SPAN = 0\n",
    "\n",
    "for split in ['train', 'test', 'validation']:\n",
    "    \n",
    "    for col_name in ['am_spans_new', 'ac_spans_new', 'feature_spans_new']:\n",
    "        \n",
    "        for x in dataset[split][col_name]:\n",
    "            \n",
    "            if max(x,key=itemgetter(1))[1] > MAX_SPAN:\n",
    "                \n",
    "                MAX_SPAN = max(x,key=itemgetter(1))[1]\n",
    "                MAX_SPAN = min(MAX_SPAN, tokenizer.model_max_length - 2)\n",
    "            \n",
    "            if len(x) > MAX_LENGTH:\n",
    "                \n",
    "                MAX_LENGTH = len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d27b9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(batch, padding_target):    \n",
    "    \n",
    "    if padding_target == 'am_spans':\n",
    "        \n",
    "        col_name = 'am_spans_new'\n",
    "        padding_val = [[-1,-1]]\n",
    "        max_length = MAX_LENGTH\n",
    "        \n",
    "    elif padding_target == 'ac_spans':\n",
    "        \n",
    "        col_name = 'ac_spans_new'\n",
    "        padding_val = [[-1,-1]]\n",
    "        max_length = MAX_LENGTH\n",
    "        \n",
    "    elif padding_target == 'fts_spans':\n",
    "        \n",
    "        col_name = 'feature_spans_new'\n",
    "        padding_val = [[-1,-1]]\n",
    "        max_length = MAX_LENGTH\n",
    "        \n",
    "    elif padding_target == 'label':\n",
    "    \n",
    "        col_name = 'paragraph_labels'\n",
    "        padding_val = [-100] # -1 previously       \n",
    "        max_length = MAX_LENGTH # max([len(l) for l in batch[col_name]]) # cause some batch had 4 x 10\n",
    "\n",
    "    padded_spans = []\n",
    "\n",
    "    for idx, span in enumerate(batch[col_name]):\n",
    "\n",
    "        padded_span = batch[col_name][idx] + (max_length - len(span)) * padding_val\n",
    "        padded_spans.append(padded_span)\n",
    "\n",
    "    return padded_spans         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25f8b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_spans(am_spans_ll, ac_spans_ll, fts_spans_ll):\n",
    "    \n",
    "    spans_ll = []\n",
    "    \n",
    "    for am_spans, ac_spans, fts_spans in zip(am_spans_ll, ac_spans_ll, fts_spans_ll):\n",
    "        \n",
    "        spans = []\n",
    "        \n",
    "        for am_span, ac_span, fts_span in zip(am_spans, ac_spans, fts_spans):\n",
    "            \n",
    "            for idx in [0,1]:\n",
    "                \n",
    "                if am_span[idx] > MAX_SPAN:\n",
    "                    am_span[idx] = MAX_SPAN\n",
    "                if ac_span[idx] > MAX_SPAN:\n",
    "                    ac_span[idx] = MAX_SPAN\n",
    "                if fts_span[idx] > MAX_SPAN:\n",
    "                    fts_span[idx] = MAX_SPAN\n",
    "\n",
    "            span = [am_span, ac_span, fts_span]\n",
    "            spans.extend(span)\n",
    "            \n",
    "        spans_ll.append(spans)\n",
    "\n",
    "    return spans_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9c257",
   "metadata": {},
   "source": [
    "### tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45add804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    \n",
    "    tokenized_text = tokenizer(batch['paragraph_w_fts_as_txt'], truncation=True, padding=True, max_length=512)\n",
    "    tokenized_text['label'] = get_padding(batch, 'label')\n",
    "    tokenized_text['am_spans'] = get_padding(batch, 'am_spans')\n",
    "    tokenized_text['ac_spans'] = get_padding(batch, 'ac_spans')\n",
    "    tokenized_text['fts_spans'] = get_padding(batch, 'fts_spans')\n",
    "    tokenized_text['spans'] = get_combined_spans(tokenized_text['am_spans'], tokenized_text['ac_spans'], tokenized_text['fts_spans'])      \n",
    "    \n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7a0e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(tokenize, batched=True, batch_size=len(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e36e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70cfbfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'].features['spans'] = datasets.Array2D(shape=(36, 2), dtype=\"int32\")\n",
    "dataset['train'].features['spans'] = datasets.Array2D(shape=(36, 2), dtype=\"int32\")\n",
    "dataset['validation'].features['spans'] = datasets.Array2D(shape=(36, 2), dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf6207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda batch: batch, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91bb2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'token_type_ids', 'spans', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30565ecc",
   "metadata": {},
   "source": [
    "## span representation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b35af42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minus_one(t):\n",
    "    \n",
    "    return torch.where(t == 0, 0, t-1)\n",
    "\n",
    "def plus_one(t):\n",
    "    \n",
    "    return torch.where(t >= MAX_SPAN, MAX_SPAN, t+1) # changed from t == MAX_SPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fec4600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_representations(outputs, spans):\n",
    "    \n",
    "    #print('spans shape', spans.shape)\n",
    "    \n",
    "    batch_size = spans.shape[0]\n",
    "    \n",
    "    nr_span_indices = spans.shape[1]\n",
    "    \n",
    "    #print('nr span indices', nr_span_indices)\n",
    "    \n",
    "    # nr_span_indices = 24 # xxx. hardcode just to check\n",
    "    \n",
    "    idx_l_ams = range(0, nr_span_indices, 3) # [0,2,4,6 etc]\n",
    "    idx_l_acs = range(1, nr_span_indices, 3) # [1,3,5,7 etc]\n",
    "    idx_l_fts = range(2, nr_span_indices, 3)\n",
    "    \n",
    "    am_spans = spans[:, idx_l_ams, :] + 1 # adds 1 to all span indices (both am and ac) to offset for the CLS token in the input_ids.\n",
    "    ac_spans = spans[:, idx_l_acs, :] + 1\n",
    "    fts_spans = spans[:, idx_l_fts, :] + 1\n",
    "    \n",
    "    \n",
    "    # fix for [-1, +1] problem\n",
    "    \n",
    "    am_spans_minus_one = minus_one(am_spans) # xxx. added to solve bug 2\n",
    "    am_spans_plus_one = plus_one(am_spans) # xxx. added to solve bug 2\n",
    "    \n",
    "    ac_spans_minus_one = minus_one(ac_spans) # xxx. added to solve bug 2\n",
    "    ac_spans_plus_one = plus_one(ac_spans) # xxx. added to solve bug 2\n",
    "    \n",
    "    fts_spans_minus_one = minus_one(fts_spans) # xxx. added to solve bug 2\n",
    "    fts_spans_plus_one = plus_one(fts_spans) # xxx. added to solve bug 2\n",
    "    \n",
    "    \n",
    "    am_spans = am_spans.flatten(start_dim=1)\n",
    "    ac_spans = ac_spans.flatten(start_dim=1)\n",
    "    fts_spans = fts_spans.flatten(start_dim=1)\n",
    "    \n",
    "    nr_adus = ac_spans.shape[1] // 2\n",
    "    \n",
    "    \n",
    "    am_spans_minus_one = am_spans_minus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    am_spans_plus_one = am_spans_plus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    \n",
    "    ac_spans_minus_one = ac_spans_minus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    ac_spans_plus_one = ac_spans_plus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    \n",
    "    fts_spans_minus_one = fts_spans_minus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    fts_spans_plus_one = fts_spans_plus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    \n",
    "    ############# FOR AMs #################\n",
    "    \n",
    "    outputs_am = outputs[:,am_spans,:]\n",
    "    #print('outputs am juste directly from outputs:', outputs_am.shape)\n",
    "    outputs_am = torch.cat([outputs_am[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    outputs_am = outputs_am.reshape(batch_size, nr_adus * 2, -1)\n",
    "    \n",
    "    #print('outputs_ am after reshape:', outputs_am.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    outputs_am_minus_one = outputs[:,am_spans_minus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_am_minus_one = torch.cat([outputs_am_minus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_am_minus_one = outputs_am_minus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    outputs_am_plus_one = outputs[:,am_spans_plus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_am_plus_one = torch.cat([outputs_am_plus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_am_plus_one = outputs_am_plus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Now that we have outputs_am i.e. outputs at am_span indices, now create the four Kuri forumlas for AMs\n",
    "    \n",
    "    # ============== the corrected 1st one =================== \n",
    "    \n",
    "    outputs_am_first_term = torch.cat([outputs_am[:,i+1,:] - outputs_am_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1) # i + 1 here means j in kuri, i here means i in kuri\n",
    "    outputs_am_first_term = outputs_am_first_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "     # ============== the corrected 2nd one ==================\n",
    "    \n",
    "    outputs_am_second_term = torch.cat([outputs_am[:,i,:] - outputs_am_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run # changed from +1 to +2 to ensure +2 is not a problem for AMs\n",
    "    outputs_am_second_term = outputs_am_second_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    \n",
    "        # ============== the corrected third one ================== \n",
    "    \n",
    "    outputs_am_third_term = torch.cat([outputs_am_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_am_third_term = outputs_am_third_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "\n",
    "        # ============== the corrected fourth one ==================\n",
    "    \n",
    "    outputs_am_fourth_term = torch.cat([outputs_am_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run # changed from +1 to +2 to ensure +2 is not a problem for AMs\n",
    "    outputs_am_fourth_term = outputs_am_fourth_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "    am_minus_representations = torch.cat([outputs_am_first_term, outputs_am_second_term, outputs_am_third_term, outputs_am_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### am minus span representation according to kuribayashi paper is now above.\n",
    "    \n",
    "    \n",
    "    outputs_ac = outputs[:,ac_spans,:]\n",
    "    outputs_ac = torch.cat([outputs_ac[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    outputs_ac = outputs_ac.reshape(batch_size, nr_adus * 2, -1)\n",
    "    \n",
    "    \n",
    "    outputs_ac_minus_one = outputs[:,ac_spans_minus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_ac_minus_one = torch.cat([outputs_ac_minus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_ac_minus_one = outputs_ac_minus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    outputs_ac_plus_one = outputs[:,ac_spans_plus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_ac_plus_one = torch.cat([outputs_ac_plus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_ac_plus_one = outputs_ac_plus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    ### Now that we have outputs_ac i.e. outputs at ac_span indices, now create the four Kuri forumlas for ACs\n",
    "    \n",
    "    \n",
    "    # ============== the corrected first one ===================\n",
    "    \n",
    "    outputs_ac_first_term = torch.cat([outputs_ac[:,i+1,:] - outputs_ac_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_ac_first_term = outputs_ac_first_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "        # ============== the correct second one ==================\n",
    "    \n",
    "    outputs_ac_second_term = torch.cat([outputs_ac[:,i,:] - outputs_ac_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run\n",
    "    outputs_ac_second_term = outputs_ac_second_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    \n",
    "    # ============== the corrected third term ==================\n",
    "    \n",
    "    outputs_ac_third_term = torch.cat([outputs_ac_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_ac_third_term = outputs_ac_third_term.reshape(batch_size, -1, 768)\n",
    "\n",
    "    \n",
    "     # ============== the corrected fourth term ================== xxx. for .788\n",
    "    \n",
    "    outputs_ac_fourth_term = torch.cat([outputs_ac_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run\n",
    "    outputs_ac_fourth_term = outputs_ac_fourth_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "    ac_minus_representations = torch.cat([outputs_ac_first_term, outputs_ac_second_term, outputs_ac_third_term, outputs_ac_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### ac minus span representation according to kuribayashi paper is now above.\n",
    "    \n",
    "    \n",
    "     ############# FOR Fts #################\n",
    "    \n",
    "    outputs_fts = outputs[:,fts_spans,:] # am spans for checking\n",
    "    #print('outputs fts juste directly from the outputs:', outputs_fts.shape)\n",
    "    outputs_fts = torch.cat([outputs_fts[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    outputs_fts = outputs_fts.reshape(batch_size, nr_adus * 2, -1)\n",
    "    \n",
    "    #print('output fts after reshape:', outputs_fts.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    outputs_fts_minus_one = outputs[:,fts_spans_minus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_fts_minus_one = torch.cat([outputs_fts_minus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_fts_minus_one = outputs_fts_minus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    outputs_fts_plus_one = outputs[:,fts_spans_plus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_fts_plus_one = torch.cat([outputs_fts_plus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_fts_plus_one = outputs_fts_plus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    #print('outputs_fts_plus_one', outputs_fts_plus_one.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Now that we have outputs_am i.e. outputs at am_span indices, now create the four Kuri forumlas for AMs\n",
    "    \n",
    "    # ============== (batch_size x nr_adus x 768) =================== \n",
    "    \n",
    "    outputs_fts_first_term = torch.cat([outputs_fts[:,i+1,:] - outputs_fts_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1) # i + 1 here means j in kuri, i here means i in kuri\n",
    "    outputs_fts_first_term = outputs_fts_first_term.reshape(batch_size, -1, 768)\n",
    "    #print('outputs_fts_first_term:', outputs_fts_first_term.shape)\n",
    "    \n",
    "     # ============== the corrected 2nd one ==================\n",
    "    \n",
    "    outputs_fts_second_term = torch.cat([outputs_fts[:,i,:] - outputs_fts_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_fts_second_term = outputs_fts_second_term.reshape(batch_size, -1, 768)\n",
    "    #print('outputs_fts_second_term:', outputs_fts_second_term.shape)\n",
    "    \n",
    "        # ============== the corrected third one ================== \n",
    "    \n",
    "    outputs_fts_third_term = torch.cat([outputs_fts_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_fts_third_term = outputs_fts_third_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "\n",
    "        # ============== the corrected fourth one ==================\n",
    "    \n",
    "    outputs_fts_fourth_term = torch.cat([outputs_fts_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_fts_fourth_term = outputs_fts_fourth_term.reshape(batch_size, -1, 768)\n",
    "    #print('outputs_fts_fourth_term:', outputs_fts_fourth_term.shape)\n",
    "    \n",
    "    # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "    fts_minus_representations = torch.cat([outputs_fts_first_term, outputs_fts_second_term, outputs_fts_third_term, outputs_fts_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### fts minus span representation according to kuribayashi paper is now above.\n",
    "    \n",
    "#     print('am rep final:', am_minus_representations.shape)\n",
    "#     print('ac rep final:', ac_minus_representations.shape)\n",
    "#     print('fts rep final:', fts_minus_representations.shape)\n",
    "    \n",
    "\n",
    "    \n",
    "    return am_minus_representations, ac_minus_representations, fts_minus_representations                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9086da7",
   "metadata": {},
   "source": [
    "### span representation function old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e15476b",
   "metadata": {},
   "source": [
    "## custom BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14556360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTKuri(nn.Module):\n",
    "\n",
    "    def __init__(self, first_model, model_am, model_ac, model_fts, nr_classes):\n",
    "        \n",
    "        super(CustomBERTKuri, self).__init__()\n",
    "        \n",
    "        self.first_model = first_model\n",
    "        \n",
    "        self.intermediate_linear_am = nn.Linear(3072, 768)\n",
    "        self.intermediate_linear_ac = nn.Linear(3072, 768) \n",
    "        self.intermediate_linear_fts = nn.Linear(3072, 768)\n",
    "        \n",
    "        self.model_am = model_am\n",
    "        self.model_ac = model_ac\n",
    "        self.model_fts = model_fts\n",
    "        \n",
    "        self.nr_classes = nr_classes\n",
    "                \n",
    "        self.fc = nn.Linear(self.model_am.config.hidden_size + self.model_ac.config.hidden_size + self.model_fts.config.hidden_size, self.nr_classes)\n",
    "       \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        batch_tokenized, batch_spans = inputs \n",
    "        outputs = self.first_model(batch_tokenized)[0]       \n",
    "        am_minus_representations, ac_minus_representations, fts_minus_representations = get_span_representations(outputs, batch_spans)\n",
    "\n",
    "\n",
    "        am_minus_representations = self.intermediate_linear_am(am_minus_representations)\n",
    "        ac_minus_representations = self.intermediate_linear_ac(ac_minus_representations)\n",
    "        fts_minus_representations = self.intermediate_linear_fts(fts_minus_representations)\n",
    "        \n",
    "\n",
    "        output_model_am = self.model_am(inputs_embeds = am_minus_representations)[0]\n",
    "        output_model_ac = self.model_ac(inputs_embeds = ac_minus_representations)[0]\n",
    "        output_model_fts = self.model_fts(inputs_embeds = fts_minus_representations)[0]\n",
    "\n",
    "        adu_representations = torch.cat([output_model_am, output_model_ac, output_model_fts], dim=-1)\n",
    "        output = self.fc(adu_representations)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e2eb7",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14d12304",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 40\n",
    "BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce936d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_model = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e0aeee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_am = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a97bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ac = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ffe154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fts = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4d3b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = CustomBERTKuri(first_model, model_am, model_ac, model_fts, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b2b10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3137fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=- 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4c66732",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(custom_model.parameters(), lr=0.0035111917342151295)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5608b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_BATCHES = len(dataset['train']) / BATCH_SIZE\n",
    "num_training_steps = NB_EPOCHS * NR_BATCHES\n",
    "num_warmup_steps = int(0.2 * num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2327402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(current_step: int):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return max(\n",
    "            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        )\n",
    "\n",
    "    # return LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2067a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4805a22",
   "metadata": {},
   "source": [
    "### create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "279403d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset['train'], batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset['validation'], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fdb4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(list_of_lists):\n",
    "    return [x for sublist in list_of_lists for x in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "451745d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dummy_labels(test_preds, test_labels):\n",
    "    \n",
    "    idxes = []\n",
    "    test_labels_l = []\n",
    "    for idx, val in enumerate(test_labels):\n",
    "        if val != -100:\n",
    "            idxes.append(idx)\n",
    "            test_labels_l.append(val)\n",
    "    \n",
    "    test_preds_l = []\n",
    "    for idx, val in enumerate(test_preds):\n",
    "        for good_idx in idxes:\n",
    "            if idx == good_idx:\n",
    "                test_preds_l.append(val)\n",
    "        \n",
    "    return test_preds_l, test_labels_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2638b77",
   "metadata": {},
   "source": [
    "## training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "546e7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss=None, optimizer=None, train_dataloader=None, val_dataloader=None, nb_epochs=20):\n",
    "    \"\"\"Training loop\"\"\"\n",
    "\n",
    "    min_f1 = -torch.inf\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Iterrate over epochs\n",
    "    for e in range(nb_epochs):\n",
    "\n",
    "        # Training\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(tqdm(train_dataloader)):            \n",
    "            \n",
    "            #print(i)\n",
    "            # unpack batch             \n",
    "            labels = batch['label'].to(device)\n",
    "            spans = batch['spans'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            \n",
    "            inputs = input_ids, spans\n",
    "            \n",
    "            # Reset gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute training loss\n",
    "            current_loss = loss(outputs.flatten(0,1), labels.flatten())\n",
    "            train_loss += current_loss.detach().item()\n",
    "\n",
    "            # Compute gradients\n",
    "            current_loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()            \n",
    "            \n",
    "            del batch\n",
    "        \n",
    "        scheduler.step()\n",
    "            \n",
    "        \n",
    "        # Validation\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        # torch.cuda.empty_cache()\n",
    "        \n",
    "        # Put model in eval mode\n",
    "        model.eval()\n",
    "        \n",
    "        preds_l = []\n",
    "        labels_l = []\n",
    "        \n",
    "        for batch in tqdm(val_dataloader):            \n",
    "            \n",
    "            # unpack batch             \n",
    "            labels = batch['label'].to(device)\n",
    "            spans = batch['spans'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            \n",
    "            inputs = input_ids, spans\n",
    "            \n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute validation loss\n",
    "            current_loss = loss(outputs.flatten(0,1), labels.flatten())\n",
    "            val_loss += current_loss.detach().item()\n",
    "            \n",
    "            preds_for_f1 = torch.argmax(outputs, dim=2).flatten().tolist()\n",
    "            labels_for_f1 = labels.flatten().tolist()\n",
    "            \n",
    "            preds_l.append(preds_for_f1)\n",
    "            labels_l.append(labels_for_f1)\n",
    "            \n",
    "            del batch\n",
    "        \n",
    "        # Prints\n",
    "        \n",
    "        preds_l = flatten_list(preds_l)\n",
    "        labels_l = flatten_list(labels_l)\n",
    "        \n",
    "        preds_l, labels_l = remove_dummy_labels(preds_l, labels_l)\n",
    "        \n",
    "        f1_score_epoch = f1_score(preds_l, labels_l, average='macro')        \n",
    "        \n",
    "        print(f\"Epoch {e+1}/{nb_epochs} \\\n",
    "                \\t Training Loss: {train_loss/len(train_dataloader):.3f} \\\n",
    "                \\t Validation Loss: {val_loss/len(val_dataloader):.3f} \\\n",
    "                \\t F1 score: {f1_score_epoch}\")\n",
    "        \n",
    "        train_losses.append(train_loss/len(train_dataloader))\n",
    "        val_losses.append(val_loss/len(val_dataloader))\n",
    "        \n",
    "\n",
    "        # Save model if val loss decreases\n",
    "        if f1_score_epoch > min_f1:\n",
    "\n",
    "            min_f1 = f1_score_epoch\n",
    "            torch.save(model.first_model.state_dict(), 'first_model.pt')\n",
    "            torch.save(model.model_am.state_dict(), 'model_am.pt')\n",
    "            torch.save(model.model_ac.state_dict(), 'model_ac.pt')\n",
    "            torch.save(model.model_fts.state_dict(), 'model_fts.pt')\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48a47a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.10s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40                 \t Training Loss: 0.739                 \t Validation Loss: 0.739                 \t F1 score: 0.37705500559741384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.07s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40                 \t Training Loss: 0.610                 \t Validation Loss: 0.602                 \t F1 score: 0.7005315304197592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40                 \t Training Loss: 0.518                 \t Validation Loss: 0.513                 \t F1 score: 0.7617270806928601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40                 \t Training Loss: 0.446                 \t Validation Loss: 0.532                 \t F1 score: 0.7417231555162589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40                 \t Training Loss: 0.384                 \t Validation Loss: 0.718                 \t F1 score: 0.6603955909569851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40                 \t Training Loss: 0.363                 \t Validation Loss: 0.600                 \t F1 score: 0.7342271796039153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40                 \t Training Loss: 0.270                 \t Validation Loss: 0.565                 \t F1 score: 0.7574495818096239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40                 \t Training Loss: 0.224                 \t Validation Loss: 0.860                 \t F1 score: 0.6920308934526944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40                 \t Training Loss: 0.208                 \t Validation Loss: 0.764                 \t F1 score: 0.7436790229269339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40                 \t Training Loss: 0.219                 \t Validation Loss: 0.875                 \t F1 score: 0.6995290423861853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40                 \t Training Loss: 0.183                 \t Validation Loss: 0.984                 \t F1 score: 0.709650668368677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40                 \t Training Loss: 0.209                 \t Validation Loss: 0.713                 \t F1 score: 0.7232224833816887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40                 \t Training Loss: 0.186                 \t Validation Loss: 0.750                 \t F1 score: 0.689788621352353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40                 \t Training Loss: 0.214                 \t Validation Loss: 0.782                 \t F1 score: 0.6717227367633871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40                 \t Training Loss: 0.207                 \t Validation Loss: 0.800                 \t F1 score: 0.6692264257481648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40                 \t Training Loss: 0.207                 \t Validation Loss: 1.000                 \t F1 score: 0.6564692425152231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40                 \t Training Loss: 0.220                 \t Validation Loss: 0.998                 \t F1 score: 0.6948812843261513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40                 \t Training Loss: 0.216                 \t Validation Loss: 0.731                 \t F1 score: 0.6988168756895218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40                 \t Training Loss: 0.345                 \t Validation Loss: 0.695                 \t F1 score: 0.6388980716253445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40                 \t Training Loss: 0.444                 \t Validation Loss: 0.845                 \t F1 score: 0.6454128424580928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40                 \t Training Loss: 0.428                 \t Validation Loss: 0.670                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40                 \t Training Loss: 0.390                 \t Validation Loss: 0.748                 \t F1 score: 0.6347267977450846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40                 \t Training Loss: 0.326                 \t Validation Loss: 0.768                 \t F1 score: 0.6417860675299221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40                 \t Training Loss: 0.296                 \t Validation Loss: 0.891                 \t F1 score: 0.6497543242163905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40                 \t Training Loss: 0.686                 \t Validation Loss: 0.683                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40                 \t Training Loss: 0.680                 \t Validation Loss: 0.698                 \t F1 score: 0.28421839940164545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.07s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40                 \t Training Loss: 0.683                 \t Validation Loss: 0.687                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40                 \t Training Loss: 0.683                 \t Validation Loss: 0.674                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40                 \t Training Loss: 0.680                 \t Validation Loss: 0.678                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40                 \t Training Loss: 0.685                 \t Validation Loss: 0.674                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40                 \t Training Loss: 0.682                 \t Validation Loss: 0.680                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40                 \t Training Loss: 0.685                 \t Validation Loss: 0.676                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40                 \t Training Loss: 0.679                 \t Validation Loss: 0.671                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/40                 \t Training Loss: 0.700                 \t Validation Loss: 0.673                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/40                 \t Training Loss: 0.681                 \t Validation Loss: 0.677                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/40                 \t Training Loss: 0.680                 \t Validation Loss: 0.672                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40                 \t Training Loss: 0.678                 \t Validation Loss: 0.674                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/40                 \t Training Loss: 0.679                 \t Validation Loss: 0.680                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/40                 \t Training Loss: 0.679                 \t Validation Loss: 0.673                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40                 \t Training Loss: 0.680                 \t Validation Loss: 0.691                 \t F1 score: 0.37614080834419816\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train(custom_model, loss, optimizer, train_dataloader, val_dataloader, NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994f3e3",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "295bf7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(dataset['test'], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c881e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_model = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "first_model.load_state_dict(torch.load('first_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_am = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "model_am.load_state_dict(torch.load('model_am.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ac = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "model_ac.load_state_dict(torch.load('model_ac.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fts = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "model_fts.load_state_dict(torch.load('model_fts.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64609a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "\n",
    "custom_model_2 = CustomBERTKuri(first_model, model_am, model_ac, model_fts, 2)\n",
    "custom_model_2.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "custom_model_2.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "839432b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_dataloader=None):\n",
    "    \n",
    "    \"\"\"Prediction loop\"\"\"\n",
    "\n",
    "    preds_l = []\n",
    "    labels_l = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch in test_dataloader:            \n",
    "            \n",
    "        # unpack batch             \n",
    "        labels = batch['label'].to(device).flatten().tolist()\n",
    "        spans = batch['spans'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        \n",
    "        inputs = input_ids, spans\n",
    "\n",
    "        # get output\n",
    "        \n",
    "        raw_preds = model(inputs).to('cpu')\n",
    "        # print(raw_preds.shape)\n",
    "        raw_preds = raw_preds.detach()#.numpy()\n",
    "\n",
    "        # Compute argmax\n",
    "        \n",
    "        predictions = torch.argmax(raw_preds, dim=2).flatten().tolist()\n",
    "        preds_l.append(predictions)\n",
    "        labels_l.append(labels)        \n",
    "        \n",
    "        del batch\n",
    "            \n",
    "    return flatten_list(preds_l), flatten_list(labels_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e21ef957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_preds, test_labels = predict(custom_model_2, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f8a504f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -100      0.000     0.000     0.000      3033\n",
      "           0      0.149     0.705     0.247       518\n",
      "           1      0.323     0.804     0.461       745\n",
      "\n",
      "    accuracy                          0.224      4296\n",
      "   macro avg      0.158     0.503     0.236      4296\n",
      "weighted avg      0.074     0.224     0.110      4296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, test_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c7ce1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_l, test_labels_l = remove_dummy_labels(test_preds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5328d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.714     0.705     0.709       518\n",
      "           1      0.797     0.804     0.800       745\n",
      "\n",
      "    accuracy                          0.763      1263\n",
      "   macro avg      0.755     0.754     0.755      1263\n",
      "weighted avg      0.763     0.763     0.763      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels_l, test_preds_l, digits=3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6241c0bc",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.714     0.705     0.709       518\n",
    "           1      0.797     0.804     0.800       745\n",
    "\n",
    "    accuracy                          0.763      1263\n",
    "   macro avg      0.755     0.754     0.755      1263\n",
    "weighted avg      0.763     0.763     0.763      1263\n",
    "\n",
    "hyper-params: epochs = 40, batch-size = 24, lr = 0.0035111917342151295, dataset column = paragraph_w_fts_as_txt, default models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
